{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCS 275 Spring 2024 Worksheet 8 Solutions\n",
    "\n",
    "* Course instructor: Emily Dumas\n",
    "* Contributors to this document: Karoline Dubin, Johnny Joyce, Kylash Viswanathan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics\n",
    "\n",
    "We've covered a lot of small topics lately; this worksheet includes:\n",
    "* `set` and `defaultdict`\n",
    "* CSV and JSON\n",
    "* Bitmap images using Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Save and load trees as JSON files\n",
    "\n",
    "*Involves recursion, trees, and JSON*\n",
    "\n",
    "Recall that we have two classes for building trees:\n",
    "* `Node`, for generic binary trees\n",
    "* `BST`, a subclass for binary search trees\n",
    "\n",
    "Consider the following binary tree, made of `Node` objects:\n",
    "```text\n",
    "-            <True>\n",
    "-            /    \\\n",
    "-     <\"Alice\">  <False>\n",
    "-      /     \\\n",
    "-   <5.8>   <5.5>\n",
    "```\n",
    "If we wanted to save the tree to a file, JSON would be a natural choice as it allows nesting of data structures.  You can't write an arbitrary object (like `Node` or `BST`) to a JSOn file, but the tree above might be saved to a JSON file by creating a nested dictionary such as\n",
    "```python\n",
    "{\n",
    "    \"class\": \"Node\",\n",
    "    \"tree\": {\n",
    "        \"key\": True,\n",
    "        \"left\": {\n",
    "            \"key\": \"Alice\",\n",
    "            \"left\": {\n",
    "                \"key\": 5.8,\n",
    "                \"left\": None,\n",
    "                \"right\": None\n",
    "            },\n",
    "            \"right\": {\n",
    "                \"key\": 5.5,\n",
    "                \"left\": None,\n",
    "                \"right\": None\n",
    "            }\n",
    "        },\n",
    "        \"right\": {\n",
    "            \"key\": False,\n",
    "            \"left\": None,\n",
    "            \"right\": None\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "and then writing *that* to a file.\n",
    "\n",
    "That would result in a JSON file with two top-level keys: `\"class\"` indicates what kind of tree it is (`BST` or `Node`), and `\"tree\"` maps to a hierarchy of objects that represent the nodes of the tree.\n",
    "\n",
    "The same general approach could be applied to binary search trees, too.  This BST:\n",
    "```text\n",
    "-           <6>          \n",
    "-          /   \\         \n",
    "-         /     \\        \n",
    "-      <5>     <14>      \n",
    "-      /        /  \\     \n",
    "-   <4>      <10>  <16> \n",
    "```\n",
    "Could be saved to a JSON file as the dictionary\n",
    "```python\n",
    "{\n",
    "    \"class\": \"BST\",\n",
    "    \"tree\": {\n",
    "        \"key\": 6,\n",
    "        \"left\": {\n",
    "            \"key\": 5,\n",
    "            \"left\": {\n",
    "                \"key\": 4,\n",
    "                \"left\": None,\n",
    "                \"right\": None\n",
    "            },\n",
    "            \"right\": None\n",
    "        },\n",
    "        \"right\": {\n",
    "            \"key\": 14,\n",
    "            \"left\": {\n",
    "                \"key\": 10,\n",
    "                \"left\": None,\n",
    "                \"right\": None\n",
    "            },\n",
    "            \"right\": {\n",
    "                \"key\": 16,\n",
    "                \"left\": None,\n",
    "                \"right\": None\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Add a method `save(fp)` to class `Node` in `trees.py` that will save a tree as JSON, writing it to an open file object `fp`.\n",
    "\n",
    "Then, add a function to the module `trees.py` called `load(fp)` that takes an open file object, reads a JSON object from it, and then builds and returns the corresponding tree.  The return type should be either `Node` or `BST` depending on what is found in the JSON file.\n",
    "\n",
    "Suggestions / hints:\n",
    "* At first, ignore the `BST` case and build a version that works for `Node` objects.  In fact, ignore the `BST` case entirely unless you have time to add that at the end.\n",
    "* A key step is converting a tree to a collection of nested dictionaries.  I suggest making a separate method of `Node` called `as_dict_tree()` that handles this naturally recursive operation.  Then you can handle the top-level object creation (with `\"class\"` and `\"tree\"` keys) in the method `save` itself.\n",
    "* A dictionary like `{\"Node\": Node, \"BST\": BST}` can be used to map names of classes to actual classes.  That allows you to build a `Node` or `BST` object depending on a string, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_classes = {\"Node\": Node, \"BST\": BST}\n",
    "\n",
    "k = \"Node\"\n",
    "A = node_classes[k](key=5)\n",
    "# Now A is a Node object\n",
    "\n",
    "k = \"BST\"\n",
    "B = node_classes[k](key=11)\n",
    "# Now B is a BST object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're done, the following code should build a BST, save it to a file, and load it back again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trees import load, BST\n",
    "from treevis import treeprint\n",
    "\n",
    "T = BST()\n",
    "T.insert(8)\n",
    "T.insert(12)\n",
    "T.insert(2)\n",
    "T.insert(3)\n",
    "\n",
    "with open(\"tree.json\",\"w\",encoding=\"UTF-8\") as fp:\n",
    "    T.save(fp)\n",
    "    \n",
    "with open(\"tree.json\",\"r\",encoding=\"UTF-8\") as fp:\n",
    "    W = load(fp)\n",
    "    \n",
    "print(\"Tree that was saved:\")\n",
    "treevis.treeprint(T)\n",
    "\n",
    "print(\"Tree that was loaded:\")\n",
    "treevis.treeprint(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the class `Node`: (Note that this will also define the function for the class `BST` too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapted older course materials prepared by TAs Johnny Joyce and Kylash Viswanathan)\n",
    "\n",
    "    def as_dict_tree(self):\n",
    "        \"\"\"\n",
    "        Returns representation of the nodes in the tree\n",
    "        as a collection of nested dictionaries.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize left and right keys as None so they can be overwritten if needed\n",
    "        D = {\"key\": self.key, \"left\": None, \"right\": None}\n",
    "\n",
    "        if self.left != None:\n",
    "            D[\"left\"] = self.left.as_dict_tree()\n",
    "\n",
    "        if self.right != None:\n",
    "            D[\"right\"] = self.right.as_dict_tree()\n",
    "\n",
    "        return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also inside the class `Node` (be sure to `import json`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(self, fp):\n",
    "    \"\"\"\n",
    "    Make a JSON representation of the tree and write it to\n",
    "    the already-open file object `fp`.\n",
    "    \"\"\"\n",
    "    tree = self.as_dict_tree()\n",
    "    json.dump({\"class\": self.__class__.__name__, \"tree\": tree}, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In another file, define the `load` function (along with a recursive helper function called `dict_tree_to_nodes` to turn dictionaries into `Node`s or `BST`s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_tree_to_nodes(D, node_type):\n",
    "    \"\"\"\n",
    "    Converts a nested dict to binary tree using `node_type`\n",
    "    as the node class (should be `Node` or `BST`).\n",
    "    \"\"\"\n",
    "    N = node_type(D[\"key\"])\n",
    "\n",
    "    if D[\"left\"] != None:  # Recursive call on left side if needed\n",
    "        N.set_left(dict_tree_to_nodes(D[\"left\"], node_type))\n",
    "\n",
    "    if D[\"right\"] != None:  # Recursive call on right side if needed\n",
    "        N.set_right(dict_tree_to_nodes(D[\"right\"], node_type))\n",
    "\n",
    "    return N\n",
    "\n",
    "def load(fp):\n",
    "    \"\"\"\n",
    "    Loads a tree from a JSON object read from `fp`\n",
    "    (which should be a file object open for reading)\n",
    "    \"\"\"\n",
    "    T = json.load(fp)\n",
    "    node_type = {\"Node\": Node, \"BST\": BST}[T[\"class\"]]\n",
    "    return dict_tree_to_nodes(T[\"tree\"], node_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pixel art color palette generator\n",
    "\n",
    "*Involves Pillow, CSV, and optionally set and defaultdict.*\n",
    "\n",
    "*I recommend working on this problem in a Python notebook.*\n",
    "\n",
    "Imagine you're a developer working on a project where many pixel art images will be incorporated into an application (e.g. a game, a GUI program, etc.).  A few of these images have already been drawn by various artists, and those artists were free to choose any colors they liked when doing so.  Here are links to those images:\n",
    "\n",
    "* [ws8-pixelart1-med.png](images/ws8-pixelart1-med.png)\n",
    "\n",
    "![](images/ws8-pixelart1-med.png)\n",
    "\n",
    "* [ws8-pixelart2-med.png](images/ws8-pixelart2-med.png)\n",
    "\n",
    "![](images/ws8-pixelart2-med.png)\n",
    "\n",
    "* [ws8-pixelart3-med.png](images/ws8-pixelart3-med.png)\n",
    "\n",
    "![](images/ws8-pixelart3-med.png)\n",
    "\n",
    "But now there is a plan to standardize on a palette of a few colors, and to draw all remaining images using only that color palette.\n",
    "\n",
    "Your task is to analyze the existing images and generate a list of the **distinct** colors that are used in them.  Ideally, the list should be ordered from most-frequently used colors (in terms of number of pixels) to least-frequently used.  However, if sorting by frequency proves to be too complicated, it's acceptable to simply produce a list of distinct colors in arbitrary order.\n",
    "\n",
    "Make a program that does this, and which outputs the list in two ways:\n",
    "1. As a CSV file `palette.csv` that has three columns, named `red`, `green`, and `blue`, and whose rows contain the distinct colors appearing in the sample images.  Its contents might look like this, for example:\n",
    "```text\n",
    "red,green,blue\n",
    "18,210,194\n",
    "241,231,108\n",
    "...\n",
    "```\n",
    "2. An image file `palette.png` that is created by the program in which 32 of the colors are shown in a horizontal strip, with each one represented by a 16x64 (width x height) pixel rectangle filled with that color.  (Thus the image has dimensions 512x64.)  Here's a sample of what it might look like, but this sample doesn't show the colors listed above nor colors that necessarily appear in the sample images.\n",
    "![](images/ws8-sample-palette.png)\n",
    "\n",
    "### Follow-up question\n",
    "\n",
    "Do these images actually have any colors in common, or is this simply a matter of concatenating the color lists from the three images?\n",
    "\n",
    "### Note\n",
    "\n",
    "This problem provides a natural opportunity to use several things:\n",
    "* Either\n",
    "    * `defaultdict` to track how many pixels have each color, OR\n",
    "    * `set` to track the set of distinct colors (without tracking how often they are used)\n",
    "* `csv` module to handle writing the palette to CSV file\n",
    "* Pillow (`PIL` module), to manage loading of the sample images and saving of `palette.png`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution \n",
    "\n",
    "\n",
    "There are many different parts of this question, so the solution is split into separate cells.\n",
    "\n",
    "### Reading the images\n",
    "\n",
    "First, let's open all images and put them together in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "art = [ Image.open(\"ws8-pixelart{}-med.png\".format(i)) for i in range(1,4) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enumerating pixel colors\n",
    "\n",
    "Now we can define a function that finds all colors in an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_colors(img):\n",
    "    \"\"\"Return a list of the pixel colors in PIL image object `img` (one per pixel)\"\"\"\n",
    "    xs = img.size[0]\n",
    "    ys = img.size[1]\n",
    "    L = []\n",
    "    # Iterate over all pixel coords (x,y) and get corresponding color\n",
    "    for x in range(xs):\n",
    "        for y in range(ys):\n",
    "            L.append(img.getpixel( (x,y) )) # Note that (x,y) must be given as a single argument \n",
    "                                            # (I.e. inside a list or tuple)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** this will return a gigantic list---its length is the number of pixels in the image.  Ultimately, we know the list will contain many duplicate entries and counting them is our goal.\n",
    "\n",
    "If we had a large collection of images, or if the images themselves had millions of pixels, we might rethink this approach.  We could avoid ever storing such a large list by incorporating the counting and duplicate removal directly into the function that checks all the pixels.\n",
    "\n",
    "These are just a few small images, so we'll keep to the simple approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color histogram\n",
    "\n",
    "In this next cell, we'll create a list `popular_colors` that contains all colors across all images sorted by the number of times they appear. To achieve this, we use a `defaultdict` where each key is a color and each value is the number of times the color appears. After this, we can use a sorting key to sort the colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "color_frequencies = defaultdict(int)\n",
    "for img in art:\n",
    "    for c in image_colors(img):\n",
    "        color_frequencies[c] += 1\n",
    "\n",
    "def color_popularity(c):\n",
    "    \"\"\"Sorting key for sorting by number of occurrences of a single color\"\"\"\n",
    "    return color_frequencies[c]\n",
    "\n",
    "popular_colors = sorted(color_frequencies, key=color_popularity, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing CSV\n",
    "\n",
    "Now we can create the CSV file listing the distinct colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"palette.csv\",\"w\",newline=\"\",encoding=\"UTF-8\") as fp:\n",
    "    writer = csv.DictWriter(fp,fieldnames=[\"red\",\"green\",\"blue\"])\n",
    "    writer.writeheader()\n",
    "    for color in popular_colors:\n",
    "        writer.writerow({ \"red\":color[0], \"green\":color[1], \"blue\":color[2] })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing palette image\n",
    "\n",
    "Finally, we can create the palette image. Here, the part that says `[x // 16]` means that the index of `popular_colors` that we look at at should only increase when `x` has increased by 16. This means that the width of each color bar will be 16 pixels.\n",
    "\n",
    "In other words, `x//16` will be 0 for 16 iterations - then it will be 1 for 16 iterations, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are other ways to draw a box with PIL but the simplest is to\n",
    "# iterate over all pixels and compute the color for each one\n",
    "palette_img = Image.new(\"RGB\",(512,64))\n",
    "for x in range(512):\n",
    "    for y in range(64):\n",
    "        palette_img.putpixel((x,y), popular_colors[x // 16] )\n",
    "        \n",
    "palette_img.save(\"ws8s-palette.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the result:\n",
    "\n",
    "![color palette image](images/ws8s-palette.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting on shared colors\n",
    "\n",
    "Lastly, the following cell finds the number of colors shared by each image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 and 2 share 1 color(s)\n",
      "Image 1 and 3 share 1 color(s)\n",
      "Image 2 and 3 share 2 color(s)\n"
     ]
    }
   ],
   "source": [
    "def distinct_colors(img):\n",
    "    \"\"\"Set of distinct colors in given PIL image `img`\"\"\"\n",
    "    return set(image_colors(img))\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(i+1,3):\n",
    "        print(\"Image {} and {} share {} color(s)\".format(i+1, j+1,\n",
    "            len(distinct_colors(art[i]) & distinct_colors(art[j]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Surprisingly slow\n",
    "\n",
    "Here is a function that takes two strings and returns the set of characters that appear in both strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_chars(s1,s2):\n",
    "    \"\"\"Return a set of all characters that are present in both\n",
    "    strings `s1` and `s2`.\"\"\"\n",
    "    common = set()\n",
    "    for c1 in s1:\n",
    "        if c1 in s2:\n",
    "            common.add(c1)\n",
    "    return common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works.  Here's a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_chars(\"mathematics\",\"computer science\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this function is actually **needlessly slow**.  Here's an example that generates two strings that each have `50,000` characters, runs `common_chars` on them, and prints the total time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "s1 = ''.join([ random.choice([\"edfghijklmnopqrstuvwxyzzzzzzzzzzzzzzzz\"]) for _ in range(50000) ])\n",
    "s2 = ''.join([ random.choice([\"abcedfghijklmnopqrstuvw\"]) for _ in range(50000) ]) + 'z'\n",
    "\n",
    "t_start = time.time()\n",
    "both = common_chars(s1,s2)\n",
    "t_end = time.time()\n",
    "\n",
    "print(\"Common characters:\")\n",
    "print(both)\n",
    "print(\"\\nRunning time: {:.2f} seconds\".format(t_end-t_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you try this yourself, you might get a slightly different time, but it will be far from instantaneous.\n",
    "\n",
    "First, what is going on here?  It should be possible to compare millions of characters for equality per second, and there are only 100,000 characters you need to look at, right?\n",
    "\n",
    "Second, can you fix it?  (It is possible to make this function shorter, clearer, and so that it returns an answer in the example above almost instantly.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "The problem with this function is that it has an implicit nested for loop that performs `len(s1)*len(s2)` equality checks.  The expression\n",
    "```\n",
    "c1 in s2\n",
    "```\n",
    "is equivalent to the return value of this function:\n",
    "```\n",
    "def c1_in_s2():\n",
    "    for c2 in s2:\n",
    "        if c1==c2:\n",
    "            return True\n",
    "    return False\n",
    "```\n",
    "In the worst case, this function performs `len(s2)` checks, and it runs for each character of `s1`.  If `s1` and `s2` are each of length 50,000, then this becomes 2,500,000,000 equality checks.\n",
    "\n",
    "However, most strings don't have that many distinct characters, so it would be faster to:\n",
    "* Find all of the distinct characters in `s1` (and make a set out of them)\n",
    "* Find all of the distinct characters in `s2` (and make a set out of them)\n",
    "* Check which characters lie in both of these sets\n",
    "\n",
    "The time it takes to do this would be roughly proportional to `len(s1) + len(s2) + n1*n2` where `n1` is the number of distinct characters in `s1` and `n2` is the number of distinct characters in `s2`.  In most cases `n1` and `n2` will be bounded by a fixed constant (like `26`, if the strings only contain lower case letters of the alphabet), so the main contribution to the running time is proportional to the lengths of `s1` and `s2` individually, rather than their product.\n",
    "\n",
    "Here is an alternative `common_chars` function that uses this strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_chars(s1,s2):\n",
    "    \"\"\"Return a set of all characters that are present in both\n",
    "    strings `s1` and `s2`.\"\"\"\n",
    "    # By first turning s1 and s2 into sets, we have fewer characters to compare.\n",
    "    # Then we can return the intersection\n",
    "    return set(s1) & set(s2)\n",
    "\n",
    "# Another syntax option would be 'return set(s1).intersection(s2)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a timing study, showing it handles strings of length 50,000 with ease:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common characters:\n",
      "{'z', 'e', 't', 'w', 'i', 'u', 'g', 'r', 'p', 'm', 's', 'n', 'o', 'h', 'd', 'j', 'k', 'l', 'v', 'f', 'q'}\n",
      "\n",
      "Running time: 0.03 seconds\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "s1 = ''.join([ random.choice([\"edfghijklmnopqrstuvwxyzzzzzzzzzzzzzzzz\"]) for _ in range(50000) ])\n",
    "s2 = ''.join([ random.choice([\"abcedfghijklmnopqrstuvw\"]) for _ in range(50000) ]) + 'z'\n",
    "\n",
    "t_start = time.time()\n",
    "both = common_chars(s1,s2)\n",
    "t_end = time.time()\n",
    "\n",
    "print(\"Common characters:\")\n",
    "print(both)\n",
    "print(\"\\nRunning time: {:.2f} seconds\".format(t_end-t_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revision history\n",
    "\n",
    "* 2024-03-01 Initial publication"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
